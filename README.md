# Implementa√ß√£o de GAN (Generative Adversarial Network) com PyTorch

Este reposit√≥rio cont√©m uma implementa√ß√£o de uma **Rede Adversarial Geradora (GAN)**, especificamente uma DCGAN (Deep Convolutional GAN), treinada no dataset MNIST. O c√≥digo est√° dispon√≠vel no notebook `GAN.ipynb`.

Este projeto serve como uma introdu√ß√£o pr√°tica √† arquitetura de GANs, que √© a base para t√©cnicas mais avan√ßadas como a **AnoGAN**, amplamente utilizada para detec√ß√£o de anomalias em diversos campos, incluindo a engenharia de controle e automa√ß√£o.

## 1. Conceitos-Chave

De acordo com os materiais de refer√™ncia fornecidos, abaixo est√£o os conceitos fundamentais.

### 1.1. O que √© uma GAN (Generative Adversarial Network)?

Uma Rede Adversarial Geradora (GAN) √© um tipo de arquitetura de machine learning que consiste em duas redes neurais competindo entre si. Esse "jogo" permite que o sistema crie dados sint√©ticos novos e realistas. As duas redes s√£o:

* **O Gerador (Generator):** Sua fun√ß√£o √© criar dados "falsos". Ele recebe um vetor de ru√≠do aleat√≥rio (chamado de espa√ßo latente, *z*) e tenta transform√°-lo em uma sa√≠da que se pare√ßa com os dados reais (por exemplo, uma imagem de um d√≠gito escrito √† m√£o).
* **O Discriminador (Discriminator):** Sua fun√ß√£o √© atuar como um "cr√≠tico" ou "policial". Ele recebe tanto dados reais (do conjunto de treinamento) quanto dados falsos (criados pelo Gerador) e tenta classificar corretamente se o dado √© real ou falso.

Durante o treinamento, o Gerador fica progressivamente melhor em "enganar" o Discriminador, enquanto o Discriminador fica melhor em "identificar" as fraudes. Esse processo de "soma zero" (minimax) termina quando o Gerador se torna t√£o eficaz que suas sa√≠das falsas s√£o quase indistingu√≠veis das reais.

### 1.2. O que √© AnoGAN?

**AnoGAN** (e suas varia√ß√µes como a f-AnoGAN) √© uma arquitetura que aplica o conceito de GANs para a **detec√ß√£o de anomalias n√£o supervisionada**.

A principal ideia √© treinar uma GAN (Gerador e Discriminador) exclusivamente com dados **normais** (ou "saud√°veis"). Ap√≥s o treinamento, o Gerador aprendeu a "distribui√ß√£o" ou as caracter√≠sticas fundamentais dos dados normais.

Quando um novo dado (uma nova imagem, por exemplo) precisa ser testado, o processo √© o seguinte:

1.  A nova imagem √© apresentada ao sistema.
2.  O sistema tenta encontrar o vetor de ru√≠do (`z`) no espa√ßo latente que, quando passado pelo **Gerador treinado**, produz a imagem mais parecida poss√≠vel com a imagem de teste.
3.  Calcula-se uma **pontua√ß√£o de anomalia (anomaly score)**, que √© baseada no "erro de reconstru√ß√£o" (a diferen√ßa entre a imagem de teste e a imagem gerada).

Se a imagem de teste for **normal**, o Gerador (que s√≥ viu dados normais) conseguir√° recri√°-la com facilidade, resultando em um **erro baixo**. Se a imagem de teste for uma **anomalia** (algo que o Gerador nunca viu durante o treino), ele falhar√° em recri√°-la fielmente, resultando em um **erro alto**. Esse erro alto sinaliza que o dado √© uma anomalia.

## 2. Import√¢ncia para Engenharia de Controle e Automa√ß√£o

As arquiteturas GAN e AnoGAN t√™m um impacto significativo na engenharia de controle e automa√ß√£o, principalmente para garantir seguran√ßa, qualidade e efici√™ncia em sistemas
* **Manuten√ß√£o Preditiva e Detec√ß√£o de Falhas:** Em um sistema de automa√ß√£o (como uma linha de montagem ou uma turbina), sensores monitoram vibra√ß√£o, temperatura, press√£o e som. Uma AnoGAN pode ser treinada usando dados desses sensores durante a opera√ß√£o **normal** (saud√°vel) da m√°quina. O sistema pode, ent√£o, monitorar a m√°quina em tempo real. Qualquer desvio nos dados dos sensores (que gere um alto "erro de reconstru√ß√£o" na AnoGAN) √© classificado como uma anomalia. Isso permite que engenheiros de controle identifiquem uma falha iminente (ex: um rolamento desgastado) **antes** que ela cause uma parada catastr√≥fica, habilitando a manuten√ß√£o preditiva.

* **Controle de Qualidade Automatizado (Vis√£o Computacional):** Em linhas de produ√ß√£o automatizadas, c√¢meras inspecionam produtos (ex: placas de circuito, soldas, tecidos). Treinar um sistema de vis√£o para encontrar *todos* os defeitos poss√≠veis √© dif√≠cil, pois os defeitos podem ser raros ou imprevis√≠veis. Com a AnoGAN, o sistema √© treinado apenas com imagens de produtos **perfeitos**. Qualquer produto que apresente um defeito visual (um arranh√£o, um componente desalinhado) ser√° marcado como uma anomalia, sendo automaticamente rejeitado pelo sistema de controle.

* **Simula√ß√£o e Gera√ß√£o de Dados (Digital Twins):** Controladores robustos precisam ser testados em cen√°rios de falha, que muitas vezes s√£o raros e perigosos de se replicar em equipamentos reais. As GANs (o Gerador) podem ser usadas para **gerar dados sint√©ticos realistas** que simulam essas falhas raras (ex: picos de sensor, falhas de atuador). Esses dados sint√©ticos podem ser usados para treinar controladores mais seguros ou para validar "G√™meos Digitais" (Digital Twins) do processo industrial.

## 3. Sobre esta Implementa√ß√£o (`GAN.ipynb`)

Este notebook foca no primeiro passo: construir a GAN base. Ele **n√£o** √© uma AnoGAN, mas implementa o Gerador e o Discriminador que s√£o os componentes centrais de uma AnoGAN.

* **Framework:** PyTorch
* **Dataset:** MNIST (d√≠gitos escritos √† m√£o, normalizados para `[-1, 1]`)
* **Arquitetura:**
    * `Generator`: Usa camadas `ConvTranspose2d` (transposi√ß√£o convolucional) para fazer o *upsampling* do vetor latente (`z`) de 100 dimens√µes at√© uma imagem 1x28x28.
    * `Discriminator`: Usa camadas `Conv2d` (convolucional) para fazer o *downsampling* de uma imagem 1x28x28 at√© uma √∫nica previs√£o (Real/Falsa).
* **Treinamento:** O notebook itera por 50 √©pocas, treinando alternadamente o Discriminador e o Gerador. O progresso √© visualizado usando `tqdm`.
* **Resultado:** O modelo treinado do Gerador √© salvo em `generator_mnist.pth`. A se√ß√£o final do notebook carrega este arquivo e gera 16 imagens sint√©ticas de d√≠gitos.
### üñºÔ∏è Imagens Geradas pelo Modelo

<img width="508" height="505" alt="image" src="https://github.com/user-attachments/assets/2f601992-6a29-4792-a816-aa5587397c89" />


## 4. Como Usar

### Pr√©-requisitos

Voc√™ precisar√° das seguintes bibliotecas Python:
* `torch`
* `torchvision`
* `matplotlib`
* `tqdm`

### Executando o Projeto

1.  **Treinamento:**
    * Abra o `GAN.ipynb` em um ambiente Jupyter (como Google Colab ou localmente).
    * Execute as c√©lulas sequencialmente. O script ir√° baixar o dataset MNIST automaticamente.
    * Ao final do treinamento (cerca de 30 minutos em uma GPU T4), o modelo `generator_mnist.pth` ser√° salvo.

2.  **Gera√ß√£o de Imagens:**
    * Execute as c√©lulas na se√ß√£o "Visualizando resultados".
    * Este script ir√° carregar o `generator_mnist.pth`, gerar 16 imagens e exibi-las usando `matplotlib`. Uma c√≥pia da grade de imagens tamb√©m ser√° salva como `generated_mnist_grid.png`.

## 5. Refer√™ncias

1.  [Guias de Machine Learning | Google Developers (PT-BR)](https://developers.google.com/machine-learning/guides?hl=pt-br)
2.  [f-AnoGAN: Fast unsupervised anomaly detection with generative adversarial networks (TUMdlma)](https://collab.dvb.bayern/spaces/TUMdlma/pages/73379950/f-AnoGAN+Fast+unsupervised+anomaly+detection+with+generative+adversarial+networks)
